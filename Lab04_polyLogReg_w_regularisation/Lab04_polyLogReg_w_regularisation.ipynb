{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Labor: Polynomiális Logisztikus regresszió Regularizációval\n",
    "\n",
    "A gyakorlat során megvizsgáljuk hogyan tudunk nem lineárisan elhatárolt csoportok közötti kalsszifikációt elvégezni a polynomiális regressziós segítségével, illetve hogyan tudjuk a modellünk súlyait kézben tartani az L1 és L2 regularizáció segítsévél."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Születés utáni komplikáció\n",
    "\n",
    "A gyakorlathoz tartozó adatsor 1000+ születés esetén tartalmazza a terhesség teljes hosszát napokban, illetve a születéskori testsúlyt kilogrammban. A célunk az lesz, hogy modellezzük ezek alapján mekkora az esély arra, hogy a baba fejlődésének korai szakaszában komplikációk lépnek fel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alultanulás (underfitting)\n",
    "\n",
    "Az előző gyakorlat során alkalmazott Logisztikus regresszió alapjául egy lineáris modellt használtunk. Bár a teljes modellt nevezhetjük nem linárisnak a _sigmoid_ függvény bevezetése miatt, a meghatározott döntési határ (_decision boundary_) a lineáris alap miatt egy egyenes volt. Bár ezzel viszonylag jól tudtuk modellezni az eredményeket, látható volt, hogy egy megfelelő görbe jobb eredményeket tudott volna adni.\n",
    "\n",
    "<!---\n",
    "<center><img src=\"img/linear_vs_poly.svg\" width=\"600\"></center>\n",
    "-->\n",
    "<center><img src=\"https://drive.google.com/uc?export=view&id=1RoiKcoYZ9CM5XODbPFp30oY74le1LDy8\" width=\"600\"></center>\n",
    "\n",
    "\n",
    "Amennyiben a modellünk nem elég komplex, hogy az adatok által leírt összefüggéseket modellezze, a kapott végeredmény a valóság egy leegyszerűsített, nem olyan pontos modellje lesz (lineáris döntési határ görbe helyett), a modellünk alultanult. A felhasználásunktól függően ez lehet, hogy megfelel a célnak, de lesznek olyan esetek, amikor szükségünk lesz a bonyolultabb modell bevezetésére."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polinomiális regresszió\n",
    "\n",
    "Ahhoz hogy a modellünk képes legyen görbe jellegű döntéshatárokat meghatározni, az alapul szolgáló lineáris illesztés helyett magasabb rendű, u.n. polinomiális regressziót kell alkalmaznunk.\n",
    "\n",
    "Lineáris regresszió két változóra:\n",
    "$$\\hat{y} = w_0 + w_1 x_1 + w_2 x_2$$\n",
    "\n",
    "Polinomiális regresszió két változóra harmadrendű polinommal:\n",
    "$$\\hat{y} = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_1^2 + w_4 x_1 x_2 + w_5 x_2 ^2 + w_6 x_1^3 + w_7 x_1^2 x_2 + w_8 x_1 x_2^2 + w_9 x_2^3$$\n",
    "\n",
    "A modellillesztés szempontjából azonban tekinthetünk a bemenetek magasabb rendű kombinációjára úgy, mintha új, független változók lennének:\n",
    "$$\\hat{y} = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 + w_5 x_5 +\\dots + w_9 x_9$$\n",
    "ahol\n",
    "$$x_3 = x_1^2; \\quad x_4 = x_1 x_2; \\quad x_5 = x_2^2; \\quad x_6 = x_1^3; \\quad x_7 = x_1^2 x_2; \\quad x_8 = x_1 x_2^2; \\quad x_9 = x_2^3$$\n",
    "\n",
    "Az új változók definiálásával egy kétváltozós harmadrendű modell illesztésének folyamata teljesen megegyezik egy kilenc változós ténylegesen lineáris regresszió illesztésével, az eltérés csupán az értelmezésben van. A bemeneti adatpontokat 2D-ben tudjuk ábrázolni, nem kell 9 különböző dimenziót használni, az illesztett modellt pedig értelmezhető egy két változó feletti harmadrendű polinomként egy 9 dimenziós síkfelület helyett."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Túltanulás (overfitting)\n",
    "\n",
    "A bonyolultabb modell bevezetésével megjelenik annak a veszélye, hogy a modell túltanul, az adatok mögötti összefüggés helyett a konkrét adatpontokat tanulja meg. Így a tanítóadatokon való értékelés esetén azt látjuk, hogy nagyon jól teljesít a modell, azonban további, a tanításhoz nem használt adatokon szignifikánsan rosszabb a teljesítménye, elvesdzíti az általánosító képességét. A gépi tanulással megoldott problémák során cél mindig a bemenetek és kimenetek közötti összefüggés betanítása, nem a konkrét adatpontok megtanulása. Bár a polinomiális logisztikus regresszió nem valószínű, hogy az ábrán látható mérétkben túltanulást fog mutatni, bonyolultabb, több nemlinearitást tartalmazó modellek (neurális hálók) esetében ez egy valós probléma lehet.\n",
    "\n",
    "<!---\n",
    "<center><img src=\"img/overfit.svg\" width=\"600\"></center>\n",
    "-->\n",
    "<center><img src=\"https://drive.google.com/uc?export=view&id=1_q4JQ7N0uL8AdBIiT11K8ConQykic7co\" width=\"600\"></center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizáció\n",
    "\n",
    "Az eddigiekben a költségfüggvényt egy szempont alapján határoztuk meg: a modellünk a lehető legpontosabban kövesse az illesztésre használt adatokat. Azonban lehetőségünk van a költségfüggvényben a pontos illesztés mellett más szempontokat is figyelembe vennünk, amivel a végleges súlyok jellegét befolyásolhatjuk. Ezt a módszert **regularizációnak** nevezzük. A regularizáció használatakor a modell illesztésének jóságát mérő tag mellett egy regularizásciós, vagyis büntető (_penalty_) taggal egészítjük ki a teljes költségfüggvényt. Egy két osztályból álló klasszifikáció esetén a költségfüggvény általános alakja:\n",
    "$$C(\\mathbf{W}) = C_{BCE}(\\mathbf{W}) + \\lambda P(\\mathbf{W})$$\n",
    "ahol $C_{BCE}(w)$ a már előző gyakorlatról ismert Binary CrossEntropy költségfüggvény, $P(\\mathbf{W})$ a regularizációból származó büntető tag, $\\lambda$ pedig a büntető tag súlyozására használt paraméter.\n",
    "\n",
    "A költségfüggvény változásával a tanulás során használt gradiensvektor is változik.  Az összegfüggvény deriválási szabálya alapján\n",
    "$$\\nabla C (\\mathbf{W}) = \\nabla C_{BCE}(\\mathbf{W}) + \\lambda \\nabla P(\\mathbf{W})$$\n",
    "Így a regularizáció hasnzálatakor nincs más teendő, mint az eddigiekben számolt gradiens mellé a megflelő büntető tag gradiensét hozzáadni, illetve a büntetés mértékét a $\\lambda$ paraméter segítségével beállítani. \n",
    "\n",
    "Az egyes regularizációs módszerek segítenek a modell túltanulását elkerülni, a modelleket a lehető legegyszerűbb vagy legáltalánosabb forma felé irányítani. A bias taghoz tartozó súlyt a feladattól függően nem mindig vetjük alá regularizációnak. A gyakorlat során kétféle regularizációs módszert nézünk meg.\n",
    "\n",
    "### L1 regularizáció (Lasso regularizáció)\n",
    "\n",
    "L1 regularizáció esetén a büntető tag a súlyok abszolút értékének összege:\n",
    "$$P_{L1}(\\mathbf{W}) = \\sum_{i=1}^n |w_i|$$\n",
    "\n",
    "A Lasso regularizáció így arra törekszik, hogy jó modellillesztés mellett a súlyok egyenként a lehető legkisebbek legyenek. Azok a súlyok, amelyek csak kis mértékben járulnak hozzá a modell jóságához a nullához fognak közelíteni. Az L1 regularizáció segíségével így a modell dimenziója 'csökkenthető', a nem releváns bemeneti paraméterek a meghatározott közel zérus súlyok alapján elhagyhatók. A végső illesztés esetében csak azok a súlyok maradnak fenn, amelyek szignifikánsan hozzájárulnak a kimenő változó magyarázásához. A modellünket így egyszerűsíthetjük, a modellillesztés mellet dimenzióredukciót is végzünk.\n",
    "\n",
    "Az L1 regularizáció esetén a gradiensvektor keigészítő tagja az egyes súlyok szignuma:\n",
    "$$ \\nabla P_{L1}(\\mathbf{W}) = sgn(\\mathbf{W})$$\n",
    "Ez alapján könnyen látható, hogy minden súlyt azok nagyságától függetlenül a 0 felé igyekszik eltolni.\n",
    "\n",
    "### L2 regularizáció (Ridge regularizáció)\n",
    "\n",
    "L1 regularizáció esetén a büntető tag a súlyok négyzetének összege (az $\\frac{1}{2}$-es szorzó csak a szebb gradiens céljábül van jelen$):\n",
    "$$P_{L2}(\\mathbf{W}) = \\frac{1}{2}\\sum_{i=1}^n w_i ^2$$\n",
    "\n",
    "A Ridge regularizáció így arra törekszik, hogy jó modellillesztés mellett kerülje a nagy súlyok használatát. A négyzetre emelés miatt a kissebb közeli súlyokat nem bünteti annyira, a nagyobb súlyokat viszont jelentősen jobban bünteti mint az L1 regularizáció. Az optimlizáció igy igyekszik eggyik bemenetre sem túlságosan támaszkodni. Ezzel növelhető a modell robosztussága és általánosító képessége.\n",
    "\n",
    "Az L2 regularizáció esetén a gradiensvektor keigészítő tagjai maguk a súlyok:\n",
    "$$ \\nabla P_{L2}(\\mathbf{W}) = \\mathbf{W}$$\n",
    "Látható, hogy ebben az esetben a regularizáció a súly nagyságával arányosan bünteti azt, azaz a nagyobb súlyra nagyobb a büntetés, kis súly esetén azonban nem szignifikáns. Az együttes hatás így, hogy minden súlyt igyekszik kis értéken tartani."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00: Könyvtár importálások\n",
    "\n",
    "Első lépésként importáljuk a feladat megoldása során használt könyvtárakat. Esetünkben ezek a következők lesznek:\n",
    "- Numpy a matematikia műveletek elvégzéséhez\n",
    "- Pandas az adatok beolvasásához és kezeléséhez\n",
    "- MatPlotLib.pyplot az eredményeink ábrázolásához\n",
    "- Plotly Express interaktív vizualizációhoz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Használjuk ezeket sötét téma esetén\n",
    "plt.style.use('dark_background')\n",
    "styleTemplate = 'plotly_dark'\n",
    "\n",
    "# Használjuk ezeket világos téma esetén\n",
    "#plt.style.use('default')\n",
    "#styleTemplate = 'plotly_white'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01: Adatbeolvasás\n",
    "Olvassuk be a szükséges adatokat az ```birthData.txt``` fájlból."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('birthData.txt', sep = ',', header = 0)    # Olvassuk be az adatokat egy Pandas DataFrame ojektumba\n",
    "df.head(10)                                                 # Irassuk ki az első 10 sort, hogy ellenőrizzük sikerült-e a beolvasás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02: Adatfelfedezés\n",
    "\n",
    "Új adthalmazzal történő első interrakció során érdemes azt először megvizsgálni, alapvető vizualizációkat ábrázolni, hogy legyen egy elsődleges \"benyomás\" az adatok jellegéről. Ábrázoljuk az adatokat egy X-Y diagrammon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formális vizualizáció MatPlotLib-el\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.scatter(df[df['complication'] == 0]['gestation'], df[df['complication'] == 0]['birthweight'], marker='o',c=\"green\", label=\"Egészséges\")\n",
    "plt.scatter(df[df['complication'] == 1]['gestation'], df[df['complication'] == 1]['birthweight'], marker='x',c=\"tomato\", label=\"Komplikáció\")\n",
    "\n",
    "plt.title(\"Születés utáni komplikációk\")\n",
    "plt.xlabel(\"Terhességi napok száma\")\n",
    "plt.ylabel(\"Születési testtömeg [kg]\")\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ez alapján látható, hogy igen nehéz lenne egy egyenes segítségével egy jó határvonalat illeszteni az adatokra, mindenképpen magasabb rendű modellt kell alkalmaznunk."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03: Adatok előkészítése\n",
    "\n",
    "A beolvasott pandas adattáblából a tanító bementeket és kimeneteket mátrixokba rendezzük."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['gestation', 'birthweight']].to_numpy()   # Bemeneti változók oszlopainak kiemelése és tömmbé konvertálása\n",
    "Y = df[['complication']].to_numpy()               # Kimeneti változó oszlopának kiemelése és tömmbé konvertálása\n",
    "\n",
    "m,n = X.shape   \n",
    "print('X:',X.shape)                               # adattömbök méretének / adatok számának kiírása\n",
    "print('Y:',Y.shape)\n",
    "print('Adatok száma',m)\n",
    "print('Változók (Feature) száma:',n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plynomiális regresszió alkalmazásához a bementi adatmátrixunkat ki kell egészítenünk az adatok magasabb rendű kombinációival. Harmadrendű polynom esetén:\n",
    "$$x_1,\\  x_2 \\Rightarrow\\ 1,\\ x_1,\\ x_2,\\ x_1^2,\\ x_1x_2,\\ x_2^2,\\ x_1^3,\\ x_1^2x_2,\\ x_1x_2^2,\\ x_2^3$$\n",
    "\n",
    "**Feladat:** implementálja a mapFeatures függvényt, amely a **két** bemeneti változó alapján legenerálja a teljes bementei mátrixot tetszőleges fokszám esetére!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapFeature(X, deg = 3):                         \n",
    "# Bemeneti változók létrehozása polinomiális regresszióhoz\n",
    "#######################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#######################################################            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = 5                     # 5-ödrendű  polinom alkalmazása\n",
    "X=mapFeature(X, deg)        # vátozók kibővítése    \n",
    "if X.shape[1] != 21:        # ellenőrzés\n",
    "    print(\"Az X mátrixban található változók száma nem megfelelő. Ellenőrizze a featureNormalise() függvény implementációját!\")\n",
    "else:\n",
    "    print(X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az újonnan előállított bemeneti adatokat természetesen normalizálnunk is kell (a bias változót leszámítva). Fontos, hogy ezt a kibővítés után tegyük meg. Ha először normalizálunk és aztán bővítünk, még mindig kaphatunk jelentősen eltérő angyságrendbe eső adatkat a bővítésénl alkalmazott magasabb hatványok miatt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureNormalize(Z): \n",
    "    mean = np.mean(Z, axis = 0)\n",
    "    mean[0] = 0\n",
    "    sigma = np.std(Z, axis = 0)\n",
    "    sigma[0] = 1\n",
    "    Z_norm = (Z-mean)/sigma\n",
    "    return Z_norm, mean, sigma                            \n",
    "\n",
    "print('Bementei adatok normalizálása ... \\n')                    \n",
    "X,Xmean,Xsigma = featureNormalize(X)                      # X standardizálása\n",
    "scaleFactors = {\"Xmean\" : Xmean, \"Xsigma\" : Xsigma}\n",
    "print('Átlagos terhességhossz és születési testtömeg:', Xmean[1:3])\n",
    "print('Terhességhossz és születési testtömeg szórása:', Xsigma[1:3], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04: Modell definiálása\n",
    "\n",
    "Az adatok előkészítése utáni következő lépés a modell és tanítási logika definiálása."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Szigmoid aktivációs függvény\n",
    "def sigmoid(z):              \n",
    "    return 1/(1+np.exp(-z))                              "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bár a regularizáció miatt eltérő a tényleges költségfüggvény ami minimalizálásra kerül, a különböző illesztések összehasonlíthatóságának érdekében a modell értékelésére az eredeti **BCE** költségfüggvényt használjuk. Így a tanítás során a költségfüggvény alakulása a tényleges illesztés jóságát fogja visszaadni a modellek értékelésére."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Költségfüggvény\n",
    "def costBCE(X,Y,W):\n",
    "   eps = 1e-15    \n",
    "   yHat = sigmoid(X@W)\n",
    "   m = Y.shape[0]\n",
    "   C = np.mean((-Y*np.log(yHat+eps))-(1-Y)*np.log(1-yHat+eps))\n",
    "   return C"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gradiensvektor számolása esetén azonban már figyelembe kell vennünk a regularizációt.\n",
    "\n",
    "**Feladat:** implementálja a gradiensvektor számítását, amely a 'regu' pareméter értékétől függően (```'None', 'L1', 'L2'```) a megfelelő gradiensvektorral tér vissza!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradiensvektor\n",
    "def findGradient(X,Y,W, lmbd, regu):    \n",
    "#######################################################   \n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "#######################################################\n",
    "   return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularizált gradiensek tesztelése\n",
    "print('''Az modell első három súlyára (bias, X1, X2) vonatkozó gradiensek \n",
    "elvárt értékei regularizáció nélkül, illetve L1 és L2 regularizáció mellett:\n",
    "[[0.68212698]\n",
    " [0.13627374]\n",
    " [0.16772988]]\n",
    "[[ 0.68212698]\n",
    " [ 1.13627374]\n",
    " [-0.83227012]]\n",
    "[[ 0.68212698]\n",
    " [ 1.01057374]\n",
    " [-0.45577012]]''')\n",
    "print()\n",
    "print('''Ugyanezen esetekre a számolt gradiens:''')\n",
    "W = np.array([[1.645], [0.8743], [-0.6235]])\n",
    "print(findGradient(X[:,:3], Y, W, lmbd = 1, regu='None'))\n",
    "print(findGradient(X[:,:3], Y, W, lmbd = 1, regu='L1'))\n",
    "print(findGradient(X[:,:3], Y, W, lmbd = 1, regu='L2'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regularizált polinomiális logisztikus regresszió implementálásának utolsó eleme az iterciós logika implementálása a megflelő regularizációt tartalamazó gradinesekkel.\n",
    "\n",
    "**Feladat:** Készítse el a regularizált logisztikus regresszió problémájat gradiens módszerrel megoldó algoritmust! Az algoritmus számolja ki a kezdeti, majd minden iteráció utáni költéségfüggvény értéket is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticGradientDescent(X, Y, W, learning_rate, epochs, lmbd, regu = 'None'):\n",
    "    C_history = np.zeros(epochs+1)\n",
    "    C_history[0] = costBCE(X,Y,W)\n",
    "######################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "######################################################\n",
    "    return W,C_history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modell viselkedésének elemzéséhez futtassuk le a tanítást azonos paraméterek mellett mindhárom regularizációs módszerrel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gradiens algoritmus futtatása ...')\n",
    "epochs = 250           # epoch szám\n",
    "lmbd = 0.02             # Lambda (regularizáció súlya)\n",
    "learning_rate = 0.5     # tanulási ráta\n",
    "W = np.zeros([X.shape[1],1])  # kezdeti zérus súlyok (0;0;0)\n",
    "\n",
    "W_n, C_history_n = logisticGradientDescent(X, Y, W, learning_rate, epochs, lmbd, 'None')                             \n",
    "plt.plot(range(C_history_n.size), C_history_n, label= \"No regularization\")\n",
    "                                                       \n",
    "W_L1, C_history_L1 = logisticGradientDescent(X, Y, W, learning_rate, epochs, lmbd, 'L1')                             \n",
    "plt.plot(range(C_history_L1.size), C_history_L1, label= \"L1 regularization\")\n",
    "\n",
    "W_L2, C_history_L2 = logisticGradientDescent(X, Y, W, learning_rate, epochs, lmbd, 'L2')\n",
    "plt.plot(range(C_history_L2.size), C_history_L2, label= \"L2 regularization\")              \n",
    "\n",
    "plt.title(\"Különböző regularizációk hatása a költségre\")\n",
    "plt.xlabel(\"Iteráció\")\n",
    "plt.ylabel(\"BCE költség\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az modellünk alakalmazhatóságához és az illesztés vizsgálatához szükségünk lesz a predict függvényre, amely adott valós bemenetre (terhesség hossza napokban és újszölött súlya kilogrammban) visszatér a komplikáció valószínűségével.\n",
    "\n",
    "**Feladat**: implementálja a predict függvényt a regularizált polinomiális logisztikus regresszió esetére! Ügyeljen rá, hogy a bemeneteket most is ki kell bővítani illetve normalizálni, miellőtt a gyakoriságot megbecsüljük."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W):              # predikciós függvény\n",
    "###########################################    \n",
    "   \n",
    "   \n",
    "   \n",
    "###########################################    \n",
    "   return prob, pred                                    \n",
    "\n",
    "testScore = np.array([312,3.176])\n",
    "prob, pred = predict(testScore, W_n)            # 312 nap terhesség után 3,176 kg-al született baba komplikációs valőszínűsége\n",
    "print('''A [312 , 3.176] teszteredményekre elvárt kimenet:\n",
    "Nincs komplikáció (0), p = 0.232 valószínűséggel\n",
    "Számított: %.0f; %.4f valószínűséggel''' % (pred, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formális vizualizáció MatPlotLib-el\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Eredeti adatpontok ábrázolása\n",
    "plt.scatter(df[df['complication'] == 0]['gestation'], df[df['complication'] == 0]['birthweight'], marker='o',c=\"green\", label=\"Egészséges\")\n",
    "plt.scatter(df[df['complication'] == 1]['gestation'], df[df['complication'] == 1]['birthweight'], marker='x',c=\"tomato\", label=\"Komplikáció\")\n",
    "\n",
    "x1 = np.linspace(min(df['gestation'])-50, max(df['gestation']+10), 200)          # grid létrehozása\n",
    "x2 = np.linspace(min(df['birthweight'])-0.2, max(df['birthweight']+1.2), 200)    # második paraméter\n",
    "\n",
    "z_n=np.zeros((len(x1),len(x2)))                          # eredményváltozó 1 inicializálása\n",
    "z_L1=np.zeros((len(x1),len(x2)))                         # eredményváltozó 2  inicializálása\n",
    "z_L2=np.zeros((len(x1),len(x2)))                         # eredményváltozó 3  inicializálása\n",
    "\n",
    "for i in range(len(x1)):                                 # valószínűség számolása a teljes háló felett\n",
    "    for j in range(len(x2)):     \n",
    "        testPoint = np.array([x1[i], x2[j]])\n",
    "        z_n[i,j], _ = predict(testPoint, W_n)\n",
    "        z_L1[i,j], _ = predict(testPoint, W_L1)\n",
    "        z_L2[i,j], _ = predict(testPoint, W_L2)\n",
    "\n",
    "plt.contour(x1, x2,z_n.transpose(), 0, colors='blue')                                  # kirajzoljuk contour plottal a döntési határt\n",
    "plt.contour(x1, x2, z_L1.transpose(), 0, colors='orange')                                  # kirajzoljuk contour plottal a döntési határt\n",
    "plt.contour(x1, x2, z_L2.transpose(), 0, colors='purple')                                  # kirajzoljuk contour plottal a döntési határt\n",
    "\n",
    "plt.title(\"Születés utáni komplikációk\")\n",
    "plt.xlabel(\"Terhesség napjainak száma\")\n",
    "plt.ylabel(\"Születési testtömeg [kg]\")\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modell viselkedésének teljes megértése miatt érdemes nem csak a döntési határt, hanem a teljes illsztett felületet is ábrázolnunk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ábrázolás Plotly-val\n",
    "fig = go.Figure()\n",
    "\n",
    "# A magyarázott változót transzponálni kell a helyes megjelenítésért.\n",
    "fig.add_trace(go.Scatter3d(x=df['gestation'], y=df['birthweight'], z=df['complication'], mode= \"markers\"))\n",
    "fig.add_trace(go.Surface(x=x1, y=x2, z=z_n.T, colorscale ='Blues'))\n",
    "\n",
    "#Plot formázása\n",
    "fig.update_layout(\n",
    "    title = \"Felvétel esélyének becslése\",\n",
    "    scene = dict(\n",
    "        xaxis_title = \"Terhesség napjainak száma\",\n",
    "        yaxis_title = \"Születési testtömeg [kg]\",\n",
    "        zaxis_title = \"Komplikáció valószínűsége\"),\n",
    "    template=styleTemplate,\n",
    "    width=750,\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "#Plot megjelenítése\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Az egyes regularizációs módszerek vizsgálatához nézzük meg, hogy a súlyok hogyan alakulnak az egyes módszerekkel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''A modell végső súlyai regularizáció nélkül''')\n",
    "for (loc, value) in enumerate(W_n):\n",
    "    if value <0.1:\n",
    "        W_n[loc] = 0.0\n",
    "print(W_n)\n",
    "print()\n",
    "\n",
    "print('''A modell végső súlyai L1 regularizációval''')\n",
    "for (loc, value) in enumerate(W_L1):\n",
    "    if value <0.1:\n",
    "        W_L1[loc] = 0.0\n",
    "print(W_L1)\n",
    "print()\n",
    "\n",
    "print('''A modell végső súlyai L2 regularizációval''')\n",
    "for (loc, value) in enumerate(W_L2):\n",
    "    if value <0.1:\n",
    "        W_L2[loc] = 0.0\n",
    "print(W_L2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
